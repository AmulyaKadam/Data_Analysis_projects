{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c6722-0c56-4b6a-bf25-422740449798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import logging\n",
    "import urllib.parse\n",
    "\n",
    "# ------------------- Logging Setup -------------------\n",
    "log_formatter = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# File handler\n",
    "file_handler = logging.FileHandler(\"csv_to_mysql.log\")\n",
    "file_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# ------------------- Config -------------------\n",
    "csv_files = [\n",
    "    ('album2.csv', 'album'),\n",
    "    ('artist.csv', 'artist'),\n",
    "    ('customer.csv', 'customer'),\n",
    "    ('employee.csv', 'employee'),\n",
    "    ('genre.csv', 'genre'),\n",
    "    ('invoice.csv', 'invoice'),\n",
    "    ('invoice_line.csv', 'invoice_line'),\n",
    "    ('media_type.csv', 'media_type'),\n",
    "    ('playlist.csv', 'playlist'),\n",
    "    ('playlist_track.csv', 'playlist_track'),\n",
    "    ('track.csv', 'track')\n",
    "]\n",
    "\n",
    "folder_path = 'D:/Projects/Music_store_Project/Cvs_files'\n",
    "\n",
    "# ------------------- Database Engine -------------------\n",
    "username = \"root\"\n",
    "password = \"Amulya@2002\"   # your real password\n",
    "database = \"music_database\"\n",
    "\n",
    "# URL encode the password (important for special chars like @, !, etc.)\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{username}:{encoded_password}@localhost:3306/{database}\"\n",
    ")\n",
    "\n",
    "# ------------------- Helpers -------------------\n",
    "def auto_convert_dates(df, table_name):\n",
    "    \"\"\"\n",
    "    Convert object columns to datetime if they look like dates.\n",
    "    Logs which columns were converted.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            sample = df[col].dropna().astype(str).head(5)\n",
    "            if sample.empty:\n",
    "                continue\n",
    "            try:\n",
    "                converted = pd.to_datetime(\n",
    "                    df[col],\n",
    "                    errors=\"coerce\",\n",
    "                    dayfirst=True,\n",
    "                    infer_datetime_format=True\n",
    "                )\n",
    "                success_ratio = converted.notna().mean()\n",
    "                if success_ratio > 0.5:\n",
    "                    df[col] = converted\n",
    "                    logging.info(f\"[{table_name}] Converted column '{col}' to datetime (success: {success_ratio:.0%})\")\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"[{table_name}] Skipped column '{col}' during datetime conversion: {e}\")\n",
    "    return df\n",
    "\n",
    "# ------------------- Main Loop -------------------\n",
    "with engine.begin() as conn:  # ensures commit/rollback safely\n",
    "    for csv_file, table_name in csv_files:\n",
    "        try:\n",
    "            file_path = os.path.join(folder_path, csv_file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Replace NaN with None for SQL compatibility\n",
    "            df = df.where(pd.notnull(df), None)\n",
    "\n",
    "            # Clean column names\n",
    "            df.columns = [\n",
    "                col.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "                for col in df.columns\n",
    "            ]\n",
    "\n",
    "            # Auto-convert datetime-like columns\n",
    "            df = auto_convert_dates(df, table_name)\n",
    "\n",
    "            csv_row_count = len(df)\n",
    "            logging.info(f\"Processing {csv_file} â†’ {table_name}, rows in CSV: {csv_row_count}\")\n",
    "\n",
    "            # Insert into MySQL\n",
    "            df.to_sql(\n",
    "                name=table_name,\n",
    "                con=conn,\n",
    "                if_exists='append',\n",
    "                index=False,\n",
    "                method='multi'\n",
    "            )\n",
    "\n",
    "            # Verify row count in MySQL\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "            db_row_count = result.scalar()\n",
    "\n",
    "            logging.info(f\"Loaded {csv_row_count} rows into `{table_name}`. Total rows in table now: {db_row_count}\")\n",
    "\n",
    "            if db_row_count < csv_row_count:\n",
    "                logging.warning(f\"[{table_name}] Row count mismatch! Inserted fewer rows than CSV had.\")\n",
    "            elif db_row_count > csv_row_count:\n",
    "                logging.info(f\"[{table_name}] Table has more rows than this CSV (probably from previous loads).\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {csv_file}: {e}\")\n",
    "\n",
    "logging.info(\"ETL process completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
